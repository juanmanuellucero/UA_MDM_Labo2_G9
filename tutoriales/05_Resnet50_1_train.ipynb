{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FUENTES**:\n",
    "\n",
    "PetFinder Kaggle:\n",
    "\n",
    "https://www.kaggle.com/competitions/petfinder-adoption-prediction/data\n",
    "\n",
    "First Tutorial:\n",
    "\n",
    "https://towardsdatascience.com/how-to-train-an-image-classifier-in-pytorch-and-use-it-to-perform-basic-inference-on-single-images-99465a1e9bf5\n",
    "\n",
    "Second Deep Tutorial:\n",
    "\n",
    "https://rumn.medium.com/part-1-ultimate-guide-to-fine-tuning-in-pytorch-pre-trained-model-and-its-configuration-8990194b71e\n",
    "\n",
    "Logo Recognition API:\n",
    "\n",
    "https://heartbeat.comet.ml/logo-recognition-ios-application-using-machine-learning-and-flask-api-aec4eff3be11\n",
    "\n",
    "Hybrid (multimodal) neural network architecture : Combination of tabular, textual and image inputs:\n",
    "\n",
    "https://medium.com/@dave.cote.msc/hybrid-multimodal-neural-network-architecture-combination-of-tabular-textual-and-image-inputs-7460a4f82a2e\n",
    "\n",
    "\n",
    "\n",
    "### **INDICACIONES PREVIAS**:\n",
    "\n",
    "+ **Git**:\n",
    "    + Clonamos el repo: root de todos los repos y ponemos git clone \"url_repo\"\n",
    "    + Hacemos el checkout de la rama main: git checkout -b new-branch\n",
    "\n",
    "+ **Poetry**:\n",
    "    + Instalamos poetry: https://python-poetry.org/docs/\n",
    "    + Realizamos un Update del pyproject: poetry update\n",
    "    + Activamos el entorno que creo poetry: poetry shell\n",
    "    + Intentamos correr una celda, si nos pide seleccionar el environment y no lo vemos en la lista, cerrar y volver abrir VSC\n",
    "\n",
    "+ **Torch y CUDA**:\n",
    "    + Verificar que versión pide torch:\n",
    "        + Versión de torch instalada: poetry show (en mi caso la 1.13.1)\n",
    "        + Buscar la versión correspondiente en la documentación: https://pytorch.org/get-started/previous-versions/  (en mi caso el 11.7)\n",
    "    + Instalar CUDA para Torch (buscar la versión correspondiente de CUDA): https://developer.nvidia.com/cuda-11-7-0-download-archive\n",
    "    + Verificar que CUDA esté funcional: correr en una celda torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TrendingPc\\Documents\\Code\\REPO_TP\\UA_MDM_Labo2_G9\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from joblib import load, dump\n",
    "\n",
    "from utiles import plot_confusion_matrix\n",
    "# Verificamos que CUDA está funcional\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteo el Modelo**\n",
    "\n",
    "Teoría de Resnet: https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo modelo ResNet entrenado en Imagenet\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "# Modificar la última capa para adaptarse a tu problema específico\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = torch.nn.Linear(num_ftrs, 5) # Clasificación 5 clases\n",
    "# Configuro para usar cuda si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50 = resnet50.to(device)\n",
    "# Instancio del criterio de pérdida CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteo parámetros, directorios y funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = '../'\n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_IMAGES_DIR = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train_images\")\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"work/optuna_temp_artifacts\")\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"work/optuna_artifacts\")\n",
    "\n",
    "MODEL_NAME = '04 ResNet'\n",
    "\n",
    "MODEL_VERSION = '1.0.0'\n",
    "\n",
    "# Parametros y variables\n",
    "CREATE_PYTORCH_DIRECTORIES = 1\n",
    "SEED = 42\n",
    "BATCH_SIZE = 50\n",
    "TEST_SIZE = 0.2\n",
    "IMAGE_SIZE = 299\n",
    "CPU_CORES = os.cpu_count()\n",
    "\n",
    "# Armo el nuevo directorio de train\n",
    "new_train_directory = os.path.join(BASE_DIR, 'work/train_images_classes')\n",
    "os.makedirs(new_train_directory, exist_ok=True) # si ya existe el nombre, lo deja como está\n",
    "\n",
    "# Armo el nuevo directorio de validación\n",
    "new_val_directory = os.path.join(BASE_DIR, 'work/val_images_classes')\n",
    "os.makedirs(new_val_directory, exist_ok=True)\n",
    "\n",
    "# Definir las clases ordenadas\n",
    "class_names = ['0', '1', '2', '3', '4']\n",
    "\n",
    "# Mapear las etiquetas de las clases a números enteros consecutivos\n",
    "class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Creo las carpetas de clases dentro de los directorios\n",
    "for clase in class_names: # Una para cada clase\n",
    "   os.makedirs(os.path.join(new_train_directory, str(clase)), exist_ok=True)\n",
    "   os.makedirs(os.path.join(new_val_directory, str(clase)), exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Funciones para la carga y el preproceso\n",
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    # Calcula el factor de escala necesario para redimensionar la imagen de manera que el lado más largo tenga el tamaño deseado \n",
    "    ratio = float(IMAGE_SIZE)/max(old_size)\n",
    "    # Calcula las nuevas dimensiones de la imagen \n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # Redimensiona la imagen con el nuevo tamaño\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    # Calcula las diferencias de tamaño y agrega pixeles (color negro) en los extremos para que quede centrada y cuadrada \n",
    "    delta_w = IMAGE_SIZE - new_size[1]\n",
    "    delta_h = IMAGE_SIZE - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_image = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def load_image(pet_id):\n",
    "    path_to_image = os.path.join(PATH_TO_IMAGES_DIR, f'{pet_id}-1.jpg') # Irá a la primera imagen de la mascota\n",
    "    image = cv2.imread(path_to_image)\n",
    "    # Convierte la imagen de BGR a RGB porque estos modelos esperan ese orden de canales\n",
    "    image = cv2.convertScaleAbs(image)\n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    new_image = resize_to_square(image)\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_pet(pet_id):\n",
    "    path_to_image = os.path.join(PATH_TO_IMAGES_DIR, f'{pet_id}-1.jpg') # Irá a la primera imagen de la mascota\n",
    "    # Cargar la imagen\n",
    "    image_to_show = cv2.imread(path_to_image)\n",
    "    # Convertir a formato RGB\n",
    "    image_to_show = cv2.cvtColor(image_to_show, cv2.COLOR_BGR2RGB)\n",
    "    # Visualizar la imagen\n",
    "    plt.imshow(image_to_show)\n",
    "    plt.axis('off')  # No mostrar los ejes\n",
    "    plt.show()\n",
    "\n",
    "def visualize_image(image):\n",
    "    # Convierte la imagen a un formato de enteros (CV_8U)\n",
    "    image = cv2.convertScaleAbs(image)\n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Visualizar la imagen\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis('off')  # No mostrar los ejes\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargo y Proceso Data**\n",
    "\n",
    "Nota: Pytorch necesita que estén las imágenes en los distintos directorios según su clase y su participación en el training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completada la copia a:  ../work/train_images_classes\n",
      "Completada la copia a:  ../work/val_images_classes\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Cargo\n",
    "train_df = pd.read_csv(PATH_TO_TRAIN)\n",
    "\n",
    "# Split para validación\n",
    "train_data, val_data = train_test_split(train_df,\n",
    "                               test_size = TEST_SIZE,\n",
    "                               random_state = SEED,\n",
    "                               stratify = train_df.AdoptionSpeed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if CREATE_PYTORCH_DIRECTORIES == 1: # Poner en 0 si ya tengo las carpetas train_images_classes y val_images_classes con las imágenes copiadas\n",
    "    # Función para copiar las imágenes a los directorios correspondientes\n",
    "    def copy_imag(data, directorio_destino):\n",
    "        for index, row in data.iterrows():\n",
    "            petID = row['PetID']\n",
    "            adoption_speed = row['AdoptionSpeed']\n",
    "            \n",
    "            # Nombre del archivo de imagen\n",
    "            nombre_archivo = f\"{petID}-1.jpg\"\n",
    "            \n",
    "            # Ruta completa de la imagen de origen\n",
    "            ruta_origen = os.path.join(PATH_TO_IMAGES_DIR, nombre_archivo)\n",
    "            \n",
    "            # Ruta completa del directorio de destino\n",
    "            ruta_destino = os.path.join(directorio_destino, str(adoption_speed), nombre_archivo)\n",
    "            \n",
    "            # Verificar si el archivo de origen existe\n",
    "            if os.path.exists(ruta_origen):\n",
    "                # Copiar el archivo de origen al directorio de destino\n",
    "                shutil.copy2(ruta_origen, ruta_destino)\n",
    "        print(\"Completada la copia a: \",str(directorio_destino))\n",
    "\n",
    "    # Copiar las imágenes al directorio de train\n",
    "    copy_imag(train_data, new_train_directory)\n",
    "\n",
    "    # Copiar las imágenes al directorio de val\n",
    "    copy_imag(val_data, new_val_directory)\n",
    "\n",
    "    print(\"Proceso completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero los DataLoaders\n",
    "def create_dataloaders(train_directory, val_directory, batch_size, num_workers):\n",
    "    # Transformaciones de imagen para el conjunto de entrenamiento\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Transformaciones de imagen para el conjunto de validación (sin data augment)\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Crear conjuntos de datos para el conjunto de entrenamiento y validación\n",
    "    conjunto_entrenamiento = datasets.ImageFolder(train_directory, transform=train_transforms)\n",
    "    conjunto_validacion = datasets.ImageFolder(val_directory, transform=val_transforms)\n",
    "\n",
    "    # Asignar las clases ordenadas al conjunto de datos\n",
    "    conjunto_entrenamiento.class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "    conjunto_validacion.class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "    # Crear dataloaders para el conjunto de entrenamiento y validación\n",
    "    train_dataloader = torch.utils.data.DataLoader(conjunto_entrenamiento, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_dataloader = torch.utils.data.DataLoader(conjunto_validacion, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "# Aplico las funcion de los DataLoaders\n",
    "train_dataloader, val_dataloader = create_dataloaders(new_train_directory , new_val_directory , BATCH_SIZE, CPU_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero una lista de PetIDs con imagen en el orden en que aparecen en el data loader\n",
    "test_sample_ids = [i[0].split('/')[-1].split('-')[0] for i in val_dataloader.dataset.samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entreno**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:19<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4208 Acc: 30.81% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:10<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3894 Acc: 32.04% Kappa: 0.260\n",
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:58<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3661 Acc: 35.90% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3725 Acc: 33.54% Kappa: 0.271\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:53<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3383 Acc: 37.41% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:06<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3679 Acc: 34.51% Kappa: 0.293\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [14:41<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3119 Acc: 39.34% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:05<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3641 Acc: 35.31% Kappa: 0.308\n",
      "Training complete in 66m 20s\n",
      "Best val Acc: 35.31%\n",
      "Modelo guardado en ../work/optuna_temp_artifacts\\04 ResNet_1.0.0_20250424_002658.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_val(model, criterion, dataloaders, datasets, device, num_epochs=20, lr=0.001, momentum = 0.9 ,trial=None):\n",
    "    \n",
    "    # Instancio Stochastic Gradient Descent (SGD): Defino el parámetro del Learning Rate (define \"el paso\" en que avanzan los pesos en cada iteración) y el Momentum (pone innercia a la dirección del gradiente descendiente para que no cambie de dirección en minimos locales)\n",
    "    optimizer = optim.SGD(resnet50.parameters(), lr=lr, momentum=momentum) # Parámetros default del SGD\n",
    "    \n",
    "    #Inicializo variables\n",
    "    since = time.time()\n",
    "\n",
    "\n",
    "    #Inicializo variable de mejor kappa entre trials\n",
    "    try:\n",
    "        #Intento obtener el mejor kappa de optuna\n",
    "        previous_best = study.best_value\n",
    "    except:\n",
    "        #Si no hay, seteo -999\n",
    "        previous_best = -999\n",
    "\n",
    "    #Inicializo variables de mejor modelo y mejor accuracy y mejor kappa de este trial\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_kappa =  -999\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        #Inicializo listas de kappa true y predicted y scores para esta epoch\n",
    "        epoch_kappa_labels_true = []\n",
    "        epoch_kappa_labels_predicted = []\n",
    "        epoch_output_scores = []\n",
    "\n",
    "        #Cada epoch tiene una fase de entrenamiento y validación\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            #Inicializo variables de loss y accuracy para esta fase de epoch\n",
    "            epoch_phase_running_loss = 0.0\n",
    "            epoch_phase_running_corrects = 0\n",
    "\n",
    "            # Itero sobre los datos.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    elif phase == 'val':\n",
    "                        #Agrego los valores de kappa true y predicted para cada batch en validación\n",
    "                        epoch_kappa_labels_true.extend(labels.cpu().numpy().tolist())\n",
    "                        epoch_kappa_labels_predicted.extend(preds.cpu().numpy().tolist())\n",
    "                        outputs_np = outputs.cpu().numpy()\n",
    "                        epoch_output_scores.extend([outputs_np[i,:] for i in range(outputs_np.shape[0])])\n",
    "\n",
    "                # Statistics for each phase\n",
    "                epoch_phase_running_loss += loss.item() * inputs.size(0)\n",
    "                epoch_phase_running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                #END OF BATCH\n",
    "\n",
    "            epoch_loss = epoch_phase_running_loss / len(datasets[phase])\n",
    "            epoch_acc = epoch_phase_running_corrects.double() / len(datasets[phase])\n",
    "            \n",
    "            #Calculo el kappa para cada epoch\n",
    "            if phase == 'train':\n",
    "                #overall_train_losses.append(epoch_loss)\n",
    "                current_kappa_score = np.nan\n",
    "            else:\n",
    "                #overall_val_losses.append(epoch_loss)\n",
    "                current_kappa_score = cohen_kappa_score(epoch_kappa_labels_true,\n",
    "                                  epoch_kappa_labels_predicted,\n",
    "                                  weights = 'quadratic')\n",
    "                    \n",
    "\n",
    "\n",
    "            print(f'{phase.title()} Loss: {epoch_loss:.4f} Acc: {epoch_acc*100:.2f}% Kappa: {current_kappa_score:.3f}')\n",
    "\n",
    "            # If this is the best Epoch so far -> Deep copy the model\n",
    "            if phase == 'val' and current_kappa_score > best_kappa:\n",
    "                best_acc = epoch_acc\n",
    "                best_kappa = current_kappa_score\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "                #Best Epoch within a trial and better than previous trials\n",
    "                if trial is not None and best_kappa > previous_best:\n",
    "\n",
    "                    #Save test dataset with predictions\n",
    "                    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "                    predicted_df = pd.DataFrame({'PetID':test_sample_ids,\n",
    "                                'pred':epoch_output_scores}).merge(val_data, on='PetID')\n",
    "                    dump(predicted_df, predicted_filename)\n",
    "\n",
    "                    #Generate and save CM \n",
    "                    cm_filename = os.path.join(PATH_TO_TEMP_FILES,f'cm_{trial.study.study_name}_{trial.number}.jpg')\n",
    "                    plot_confusion_matrix(epoch_kappa_labels_true,epoch_kappa_labels_predicted).write_image(cm_filename)\n",
    "\n",
    "            #END OF PHASE\n",
    "\n",
    "        #END OF EPOCH\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.2f}%'.format(best_acc * 100))\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Save in optuna trial the best test dataset, cm and model weights\n",
    "    if trial is not None and best_kappa > previous_best:\n",
    "        upload_artifact(trial, predicted_filename, artifact_store)   \n",
    "\n",
    "        upload_artifact(trial, cm_filename, artifact_store)\n",
    "\n",
    "        file_name = f'{MODEL_NAME}_{MODEL_VERSION}_{trial.number}.pth'\n",
    "        model_path = os.path.join(PATH_TO_TEMP_FILES, file_name)\n",
    "        torch.save(model, model_path) # Podemos guardar solo los pesos si queremos: best_model.state_dict()\n",
    "        upload_artifact(trial, model_path, artifact_store)\n",
    "\n",
    "    return model,best_kappa\n",
    "\n",
    "best_model,_ = train_val(resnet50, criterion, \n",
    "                       dataloaders={'train': train_dataloader, \n",
    "                                    'val': val_dataloader}, \n",
    "                       datasets={'train': train_data, 'val': val_data}, \n",
    "                       device=device, \n",
    "                       num_epochs=4)\n",
    "# Guardo el modelo\n",
    "run_id = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f'{MODEL_NAME}_{MODEL_VERSION}_{run_id}.pth'\n",
    "model_path = os.path.join(PATH_TO_TEMP_FILES, file_name)\n",
    "torch.save(best_model, model_path) # Podemos guardar solo los pesos si queremos: best_model.state_dict()\n",
    "print(f'Modelo guardado en {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "\n",
    "def optuna_train(trial):\n",
    "\n",
    "    epochs = trial.suggest_int('epochs', 5, 5)\n",
    "\n",
    "    lr = trial.suggest_float('lr', 0.00001, 0.1, log=True)\n",
    "\n",
    "    momentum = trial.suggest_float('momentum', 0.0, 0.95)\n",
    "\n",
    "    _,best_score = train_val(resnet50, criterion,\n",
    "                       dataloaders={'train': train_dataloader, \n",
    "                                    'val': val_dataloader}, \n",
    "                       datasets={'train': train_data, 'val': val_data}, \n",
    "                       device=device, \n",
    "                       num_epochs=epochs,\n",
    "                       lr=lr,\n",
    "                       momentum = momentum,\n",
    "                       trial=trial)\n",
    "\n",
    "\n",
    "    return(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 08:46:37,935] Using an existing study with name '04 ResNet_1.0.0' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [17:25<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2874 Acc: 41.56% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3629 Acc: 35.31% Kappa: 0.312\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [18:51<00:00,  4.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2861 Acc: 41.82% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3622 Acc: 34.98% Kappa: 0.308\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:58<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2866 Acc: 41.40% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:02<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3626 Acc: 35.25% Kappa: 0.316\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [17:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2848 Acc: 41.56% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3620 Acc: 35.05% Kappa: 0.306\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:15<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2842 Acc: 41.87% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.02s/it]\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_12316\\10125482.py:127: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'file_path', 'study_or_trial', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_12316\\10125482.py:129: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'file_path', 'study_or_trial', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_12316\\10125482.py:134: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'file_path', 'study_or_trial', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3615 Acc: 35.28% Kappa: 0.311\n",
      "Training complete in 91m 42s\n",
      "Best val Acc: 35.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 10:18:20,574] Trial 6 finished with value: 0.31580521218803714 and parameters: {'epochs': 5, 'lr': 1.56968359950946e-05, 'momentum': 0.714386196389082}. Best is trial 6 with value: 0.31580521218803714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [45:33<00:00, 11.63s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2908 Acc: 41.12% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3733 Acc: 34.84% Kappa: 0.294\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:38<00:00,  3.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2522 Acc: 43.87% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:12<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3694 Acc: 35.31% Kappa: 0.311\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:52<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2058 Acc: 46.56% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3904 Acc: 34.44% Kappa: 0.283\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [18:56<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1443 Acc: 50.00% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4026 Acc: 35.55% Kappa: 0.322\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:52<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0671 Acc: 54.89% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:03<00:00,  1.07s/it]\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_12316\\10125482.py:127: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'file_path', 'study_or_trial', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_12316\\10125482.py:129: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'file_path', 'study_or_trial', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_12316\\10125482.py:134: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'file_path', 'study_or_trial', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-04-24 12:15:31,273] Trial 7 finished with value: 0.3222827596391742 and parameters: {'epochs': 5, 'lr': 0.00791988751492086, 'momentum': 0.47808486141356804}. Best is trial 7 with value: 0.3222827596391742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4599 Acc: 35.61% Kappa: 0.301\n",
      "Training complete in 117m 10s\n",
      "Best val Acc: 35.55%\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [19:41<00:00,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0576 Acc: 55.40% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:51<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4545 Acc: 35.01% Kappa: 0.287\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [10:55<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9820 Acc: 59.72% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:52<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4805 Acc: 34.81% Kappa: 0.294\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [11:45<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8803 Acc: 65.31% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5873 Acc: 34.51% Kappa: 0.286\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:44<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7710 Acc: 70.76% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.6327 Acc: 32.51% Kappa: 0.279\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:44<00:00,  4.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6437 Acc: 76.24% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.01s/it]\n",
      "[I 2025-04-24 13:34:06,137] Trial 8 finished with value: 0.2937206063068538 and parameters: {'epochs': 5, 'lr': 0.007910956782935703, 'momentum': 0.3022594778337883}. Best is trial 7 with value: 0.3222827596391742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.8013 Acc: 32.81% Kappa: 0.261\n",
      "Training complete in 78m 35s\n",
      "Best val Acc: 34.81%\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:35<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8739 Acc: 67.10% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4777 Acc: 34.14% Kappa: 0.295\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:39<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8585 Acc: 67.64% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4926 Acc: 34.08% Kappa: 0.291\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [26:17<00:00,  6.71s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8453 Acc: 68.13% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5032 Acc: 34.14% Kappa: 0.285\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:29<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8309 Acc: 68.77% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5073 Acc: 34.11% Kappa: 0.299\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:30<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8204 Acc: 69.02% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.00s/it]\n",
      "[I 2025-04-24 15:08:38,320] Trial 9 finished with value: 0.2991689151871686 and parameters: {'epochs': 5, 'lr': 0.0001008610854879581, 'momentum': 0.8991058715326183}. Best is trial 7 with value: 0.3222827596391742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5229 Acc: 34.74% Kappa: 0.297\n",
      "Training complete in 94m 32s\n",
      "Best val Acc: 34.11%\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:21<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9420 Acc: 60.80% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:58<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.8312 Acc: 32.84% Kappa: 0.200\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:23<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7526 Acc: 69.98% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:07<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.8357 Acc: 31.98% Kappa: 0.231\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:28<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5523 Acc: 78.29% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 2.0668 Acc: 31.34% Kappa: 0.230\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:27<00:00,  3.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3985 Acc: 84.46% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:59<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 2.3511 Acc: 30.98% Kappa: 0.226\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 139/235 [09:31<08:46,  5.48s/it]"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///../work/db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=f'{MODEL_NAME}_{MODEL_VERSION}',\n",
    "                            load_if_exists = True)\n",
    "study.optimize(optuna_train, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
