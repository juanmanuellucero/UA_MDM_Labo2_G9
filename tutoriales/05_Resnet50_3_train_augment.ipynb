{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FUENTES**:\n",
    "\n",
    "PetFinder Kaggle:\n",
    "\n",
    "https://www.kaggle.com/competitions/petfinder-adoption-prediction/data\n",
    "\n",
    "First Tutorial:\n",
    "\n",
    "https://towardsdatascience.com/how-to-train-an-image-classifier-in-pytorch-and-use-it-to-perform-basic-inference-on-single-images-99465a1e9bf5\n",
    "\n",
    "Second Deep Tutorial:\n",
    "\n",
    "https://rumn.medium.com/part-1-ultimate-guide-to-fine-tuning-in-pytorch-pre-trained-model-and-its-configuration-8990194b71e\n",
    "\n",
    "Logo Recognition API:\n",
    "\n",
    "https://heartbeat.comet.ml/logo-recognition-ios-application-using-machine-learning-and-flask-api-aec4eff3be11\n",
    "\n",
    "Hybrid (multimodal) neural network architecture : Combination of tabular, textual and image inputs:\n",
    "\n",
    "https://medium.com/@dave.cote.msc/hybrid-multimodal-neural-network-architecture-combination-of-tabular-textual-and-image-inputs-7460a4f82a2e\n",
    "\n",
    "\n",
    "\n",
    "### **INDICACIONES PREVIAS**:\n",
    "\n",
    "+ **Git**:\n",
    "    + Clonamos el repo: root de todos los repos y ponemos git clone \"url_repo\"\n",
    "    + Hacemos el checkout de la rama main: git checkout -b new-branch\n",
    "\n",
    "+ **Poetry**:\n",
    "    + Instalamos poetry: https://python-poetry.org/docs/\n",
    "    + Realizamos un Update del pyproject: poetry update\n",
    "    + Activamos el entorno que creo poetry: poetry shell\n",
    "    + Intentamos correr una celda, si nos pide seleccionar el environment y no lo vemos en la lista, cerrar y volver abrir VSC\n",
    "\n",
    "+ **Torch y CUDA**:\n",
    "    + Verificar que versión pide torch:\n",
    "        + Versión de torch instalada: poetry show (en mi caso la 1.13.1)\n",
    "        + Buscar la versión correspondiente en la documentación: https://pytorch.org/get-started/previous-versions/  (en mi caso el 11.7)\n",
    "    + Instalar CUDA para Torch (buscar la versión correspondiente de CUDA): https://developer.nvidia.com/cuda-11-7-0-download-archive\n",
    "    + Verificar que CUDA esté funcional: correr en una celda torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TrendingPc\\Documents\\Code\\REPO_TP\\UA_MDM_Labo2_G9\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import cv2\n",
    "#from PIL import Image\n",
    "#from pathlib import Path\n",
    "\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from joblib import load, dump\n",
    "\n",
    "from utiles import plot_confusion_matrix\n",
    "\n",
    "# Appendeo el directorio de una carpeta arriba\n",
    "nb_dir = os.path.dirname(os.path.abspath(\"05_Resnet50_3_train_augment.ipynb\"))\n",
    "dir = os.path.abspath(os.path.join(nb_dir,'..'))\n",
    "sys.path.append(dir)\n",
    "\n",
    "from augment.autoaugment import ImageNetPolicy\t\n",
    "from augment.cutout import Cutout\n",
    "# Verificamos que CUDA está funcional\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteo el Modelo**\n",
    "\n",
    "Teoría de Resnet: https://towardsdatascience.com/introduction-to-resnets-c0a830a288a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo modelo ResNet entrenado en Imagenet\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "# Modificar la última capa para adaptarse a tu problema específico\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = torch.nn.Linear(num_ftrs, 5) # Clasificación 5 clases\n",
    "# Configuro para usar cuda si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50 = resnet50.to(device)\n",
    "# Instancio del criterio de pérdida CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seteo parámetros, directorios y funciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = '../'\n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_IMAGES_DIR = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train_images\")\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"work/optuna_temp_artifacts\")\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"work/optuna_artifacts\")\n",
    "\n",
    "MODEL_NAME = '04 ResNet Augment'\n",
    "\n",
    "MODEL_VERSION = '1.0.0'\n",
    "\n",
    "# Parametros y variables\n",
    "CREATE_PYTORCH_DIRECTORIES = 1\n",
    "SEED = 42\n",
    "BATCH_SIZE = 50\n",
    "TEST_SIZE = 0.2\n",
    "IMAGE_SIZE = 299\n",
    "CPU_CORES = os.cpu_count()\n",
    "\n",
    "# Armo el nuevo directorio de train\n",
    "new_train_directory = os.path.join(BASE_DIR, 'work/train_images_classes')\n",
    "os.makedirs(new_train_directory, exist_ok=True) # si ya existe el nombre, lo deja como está\n",
    "\n",
    "# Armo el nuevo directorio de validación\n",
    "new_val_directory = os.path.join(BASE_DIR, 'work/val_images_classes')\n",
    "os.makedirs(new_val_directory, exist_ok=True)\n",
    "\n",
    "# Definir las clases ordenadas\n",
    "class_names = ['0', '1', '2', '3', '4']\n",
    "\n",
    "# Mapear las etiquetas de las clases a números enteros consecutivos\n",
    "class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Creo las carpetas de clases dentro de los directorios\n",
    "for clase in class_names: # Una para cada clase\n",
    "   os.makedirs(os.path.join(new_train_directory, str(clase)), exist_ok=True)\n",
    "   os.makedirs(os.path.join(new_val_directory, str(clase)), exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Funciones para la carga y el preproceso\n",
    "def resize_to_square(im):\n",
    "    old_size = im.shape[:2] # old_size is in (height, width) format\n",
    "    # Calcula el factor de escala necesario para redimensionar la imagen de manera que el lado más largo tenga el tamaño deseado \n",
    "    ratio = float(IMAGE_SIZE)/max(old_size)\n",
    "    # Calcula las nuevas dimensiones de la imagen \n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "    # Redimensiona la imagen con el nuevo tamaño\n",
    "    im = cv2.resize(im, (new_size[1], new_size[0]))\n",
    "    # Calcula las diferencias de tamaño y agrega pixeles (color negro) en los extremos para que quede centrada y cuadrada \n",
    "    delta_w = IMAGE_SIZE - new_size[1]\n",
    "    delta_h = IMAGE_SIZE - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    color = [0, 0, 0]\n",
    "    new_image = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def load_image(pet_id):\n",
    "    path_to_image = os.path.join(PATH_TO_IMAGES_DIR, f'{pet_id}-1.jpg') # Irá a la primera imagen de la mascota\n",
    "    image = cv2.imread(path_to_image)\n",
    "    # Convierte la imagen de BGR a RGB porque estos modelos esperan ese orden de canales\n",
    "    image = cv2.convertScaleAbs(image)\n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    new_image = resize_to_square(image)\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_pet(pet_id):\n",
    "    path_to_image = os.path.join(PATH_TO_IMAGES_DIR, f'{pet_id}-1.jpg') # Irá a la primera imagen de la mascota\n",
    "    # Cargar la imagen\n",
    "    image_to_show = cv2.imread(path_to_image)\n",
    "    # Convertir a formato RGB\n",
    "    image_to_show = cv2.cvtColor(image_to_show, cv2.COLOR_BGR2RGB)\n",
    "    # Visualizar la imagen\n",
    "    plt.imshow(image_to_show)\n",
    "    plt.axis('off')  # No mostrar los ejes\n",
    "    plt.show()\n",
    "\n",
    "def visualize_image(image):\n",
    "    # Convierte la imagen a un formato de enteros (CV_8U)\n",
    "    image = cv2.convertScaleAbs(image)\n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Visualizar la imagen\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.axis('off')  # No mostrar los ejes\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargo y Proceso Data**\n",
    "\n",
    "Nota: Pytorch necesita que estén las imágenes en los distintos directorios según su clase y su participación en el training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completada la copia a:  ../work/train_images_classes\n",
      "Completada la copia a:  ../work/val_images_classes\n",
      "Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "# Cargo\n",
    "train_df = pd.read_csv(PATH_TO_TRAIN)\n",
    "\n",
    "# Split para validación\n",
    "train_data, val_data = train_test_split(train_df,\n",
    "                               test_size = TEST_SIZE,\n",
    "                               random_state = SEED,\n",
    "                               stratify = train_df.AdoptionSpeed)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if CREATE_PYTORCH_DIRECTORIES == 1: # Poner en 0 si ya tengo las carpetas train_images_classes y val_images_classes con las imágenes copiadas\n",
    "    # Función para copiar las imágenes a los directorios correspondientes\n",
    "    def copy_imag(data, directorio_destino):\n",
    "        for index, row in data.iterrows():\n",
    "            petID = row['PetID']\n",
    "            adoption_speed = row['AdoptionSpeed']\n",
    "            \n",
    "            # Nombre del archivo de imagen\n",
    "            nombre_archivo = f\"{petID}-1.jpg\"\n",
    "            \n",
    "            # Ruta completa de la imagen de origen\n",
    "            ruta_origen = os.path.join(PATH_TO_IMAGES_DIR, nombre_archivo)\n",
    "            \n",
    "            # Ruta completa del directorio de destino\n",
    "            ruta_destino = os.path.join(directorio_destino, str(adoption_speed), nombre_archivo)\n",
    "            \n",
    "            # Verificar si el archivo de origen existe\n",
    "            if os.path.exists(ruta_origen):\n",
    "                # Copiar el archivo de origen al directorio de destino\n",
    "                shutil.copy2(ruta_origen, ruta_destino)\n",
    "        print(\"Completada la copia a: \",str(directorio_destino))\n",
    "\n",
    "    # Copiar las imágenes al directorio de train\n",
    "    copy_imag(train_data, new_train_directory)\n",
    "\n",
    "    # Copiar las imágenes al directorio de val\n",
    "    copy_imag(val_data, new_val_directory)\n",
    "\n",
    "    print(\"Proceso completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero los DataLoaders\n",
    "def create_dataloaders(train_directory, val_directory, batch_size, num_workers):\n",
    "    # Transformaciones de imagen para el conjunto de entrenamiento\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        ImageNetPolicy(),  ############### LAS POLÍTICAS AUTOAUGMENT PARA IMAGENET (AUGMENT)\n",
    "        transforms.ToTensor(),\n",
    "        Cutout(n_holes=1, length = 16),   ############### CUTOUT PARA REGULARIZACIÓN (AUGMENT)\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Transformaciones de imagen para el conjunto de validación (sin data augment)\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Crear conjuntos de datos para el conjunto de entrenamiento y validación\n",
    "    conjunto_entrenamiento = datasets.ImageFolder(train_directory, transform=train_transforms)\n",
    "    conjunto_validacion = datasets.ImageFolder(val_directory, transform=val_transforms)\n",
    "\n",
    "    # Asignar las clases ordenadas al conjunto de datos\n",
    "    conjunto_entrenamiento.class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "    conjunto_validacion.class_to_idx = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "    # Crear dataloaders para el conjunto de entrenamiento y validación\n",
    "    train_dataloader = torch.utils.data.DataLoader(conjunto_entrenamiento, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_dataloader = torch.utils.data.DataLoader(conjunto_validacion, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "# Aplico las funcion de los DataLoaders\n",
    "train_dataloader, val_dataloader = create_dataloaders(new_train_directory , new_val_directory , BATCH_SIZE, CPU_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genero una lista de PetIDs con imagen en el orden en que aparecen en el data loader\n",
    "test_sample_ids = [i[0].split('/')[-1].split('-')[0] for i in val_dataloader.dataset.samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entreno**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(model, criterion, dataloaders, datasets, device, num_epochs=20, lr=0.001, momentum = 0.9 ,trial=None):\n",
    "    \n",
    "    # Instancio Stochastic Gradient Descent (SGD): Defino el parámetro del Learning Rate (define \"el paso\" en que avanzan los pesos en cada iteración) y el Momentum (pone innercia a la dirección del gradiente descendiente para que no cambie de dirección en minimos locales)\n",
    "    optimizer = optim.SGD(resnet50.parameters(), lr=lr, momentum=momentum) # Parámetros default del SGD\n",
    "    \n",
    "    #Inicializo variables\n",
    "    since = time.time()\n",
    "\n",
    "    #Inicializo variable de mejor kappa entre trials\n",
    "    try:\n",
    "        #Intento obtener el mejor kappa de optuna\n",
    "        previous_best = study.best_value\n",
    "    except:\n",
    "        #Si no hay, seteo -999\n",
    "        previous_best = -999\n",
    "\n",
    "    #Inicializo variables de mejor modelo y mejor accuracy y mejor kappa de este trial\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_kappa =  -999\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        #Inicializo listas de kappa true y predicted y scores para esta epoch\n",
    "        epoch_kappa_labels_true = []\n",
    "        epoch_kappa_labels_predicted = []\n",
    "        epoch_output_scores = []\n",
    "\n",
    "        #Cada epoch tiene una fase de entrenamiento y validación\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            #Inicializo variables de loss y accuracy para esta fase de epoch\n",
    "            epoch_phase_running_loss = 0.0\n",
    "            epoch_phase_running_corrects = 0\n",
    "\n",
    "            # Itero sobre los datos.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                # Track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    elif phase == 'val':\n",
    "                        #Agrego los valores de kappa true y predicted para cada batch en validación\n",
    "                        epoch_kappa_labels_true.extend(labels.cpu().numpy().tolist())\n",
    "                        epoch_kappa_labels_predicted.extend(preds.cpu().numpy().tolist())\n",
    "                        outputs_np = outputs.cpu().numpy()\n",
    "                        epoch_output_scores.extend([outputs_np[i,:] for i in range(outputs_np.shape[0])])\n",
    "\n",
    "                # Statistics for each phase\n",
    "                epoch_phase_running_loss += loss.item() * inputs.size(0)\n",
    "                epoch_phase_running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "                #END OF BATCH\n",
    "\n",
    "            epoch_loss = epoch_phase_running_loss / len(datasets[phase])\n",
    "            epoch_acc = epoch_phase_running_corrects.double() / len(datasets[phase])\n",
    "            \n",
    "            #Calculo el kappa para cada epoch\n",
    "            if phase == 'train':\n",
    "                #overall_train_losses.append(epoch_loss)\n",
    "                current_kappa_score = np.nan\n",
    "            else:\n",
    "                #overall_val_losses.append(epoch_loss)\n",
    "                current_kappa_score = cohen_kappa_score(epoch_kappa_labels_true,\n",
    "                                  epoch_kappa_labels_predicted,\n",
    "                                  weights = 'quadratic')\n",
    "                    \n",
    "\n",
    "\n",
    "            print(f'{phase.title()} Loss: {epoch_loss:.4f} Acc: {epoch_acc*100:.2f}% Kappa: {current_kappa_score:.3f}')\n",
    "\n",
    "            # If this is the best Epoch so far -> Deep copy the model\n",
    "            if phase == 'val' and current_kappa_score > best_kappa:\n",
    "                best_acc = epoch_acc\n",
    "                best_kappa = current_kappa_score\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "                #Best Epoch within a trial and better than previous trials\n",
    "                if trial is not None and best_kappa > previous_best:\n",
    "\n",
    "                    #Save test dataset with predictions\n",
    "                    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "                    predicted_df = pd.DataFrame({'PetID':test_sample_ids,\n",
    "                                'pred':epoch_output_scores}).merge(val_data, on='PetID')\n",
    "                    dump(predicted_df, predicted_filename)\n",
    "\n",
    "                    #Generate and save CM \n",
    "                    cm_filename = os.path.join(PATH_TO_TEMP_FILES,f'cm_{trial.study.study_name}_{trial.number}.jpg')\n",
    "                    plot_confusion_matrix(epoch_kappa_labels_true,epoch_kappa_labels_predicted).write_image(cm_filename)\n",
    "\n",
    "            #END OF PHASE\n",
    "\n",
    "        #END OF EPOCH\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.2f}%'.format(best_acc * 100))\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Save in optuna trial the best test dataset, cm and model weights\n",
    "    if trial is not None and best_kappa > previous_best:\n",
    "        upload_artifact(trial, predicted_filename, artifact_store)   \n",
    "\n",
    "        upload_artifact(trial, cm_filename, artifact_store)\n",
    "\n",
    "        file_name = f'{MODEL_NAME}_{MODEL_VERSION}_{trial.number}.pth'\n",
    "        model_path = os.path.join(PATH_TO_TEMP_FILES, file_name)\n",
    "        torch.save(model, model_path) # Podemos guardar solo los pesos si queremos: best_model.state_dict()\n",
    "        upload_artifact(trial, model_path, artifact_store)\n",
    "\n",
    "    return model,best_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "\n",
    "def optuna_train(trial):\n",
    "\n",
    "    epochs = trial.suggest_int('epochs', 5, 5)\n",
    "\n",
    "    lr = trial.suggest_float('lr', 0.00001, 0.1, log=True)\n",
    "\n",
    "    momentum = trial.suggest_float('momentum', 0.0, 0.95)\n",
    "\n",
    "    _,best_score = train_val(resnet50, criterion, \n",
    "                       dataloaders={'train': train_dataloader, \n",
    "                                    'val': val_dataloader}, \n",
    "                       datasets={'train': train_data, 'val': val_data}, \n",
    "                       device=device, \n",
    "                       num_epochs=epochs,\n",
    "                       lr=lr,\n",
    "                       momentum = momentum,\n",
    "                       trial=trial)\n",
    "\n",
    "\n",
    "    return(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-23 13:43:24,995] Using an existing study with name '04 ResNet Augment_1.0.0' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [12:16<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5332 Acc: 25.33% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:58<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.5000 Acc: 26.21% Kappa: 0.003\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [11:52<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4791 Acc: 28.01% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:54<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4656 Acc: 27.54% Kappa: 0.050\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [12:06<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4539 Acc: 28.86% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:55<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4475 Acc: 28.81% Kappa: 0.085\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [31:27<00:00,  8.03s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4385 Acc: 30.39% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:03<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4346 Acc: 29.21% Kappa: 0.107\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [17:28<00:00,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4297 Acc: 30.67% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:03<00:00,  1.08s/it]\n",
      "[I 2025-04-23 15:13:31,635] Trial 9 finished with value: 0.1348941767850268 and parameters: {'epochs': 5, 'lr': 0.0003481467841159878, 'momentum': 0.2528580372667046}. Best is trial 6 with value: 0.3329202623857196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.4287 Acc: 29.98% Kappa: 0.135\n",
      "Training complete in 90m 7s\n",
      "Best val Acc: 29.98%\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:59<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4037 Acc: 32.49% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:58<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3855 Acc: 33.51% Kappa: 0.241\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:44<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3750 Acc: 34.92% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:02<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3770 Acc: 33.24% Kappa: 0.279\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [18:16<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3584 Acc: 36.27% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:57<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3673 Acc: 34.51% Kappa: 0.301\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:19<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3446 Acc: 37.05% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:57<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3657 Acc: 35.41% Kappa: 0.306\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [17:00<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3319 Acc: 38.53% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:56<00:00,  1.05it/s]\n",
      "[I 2025-04-23 16:43:44,291] Trial 10 finished with value: 0.3124079337413511 and parameters: {'epochs': 5, 'lr': 0.0028002045328507394, 'momentum': 0.7019566862800795}. Best is trial 6 with value: 0.3329202623857196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3616 Acc: 36.21% Kappa: 0.312\n",
      "Training complete in 90m 13s\n",
      "Best val Acc: 36.21%\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:10<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3183 Acc: 38.94% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:56<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3595 Acc: 35.31% Kappa: 0.317\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:02<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3129 Acc: 39.52% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3601 Acc: 35.18% Kappa: 0.321\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:58<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3085 Acc: 39.49% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:56<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3607 Acc: 35.28% Kappa: 0.323\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:59<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3040 Acc: 40.06% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3592 Acc: 35.21% Kappa: 0.322\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:03<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3013 Acc: 40.27% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:56<00:00,  1.04it/s]\n",
      "[I 2025-04-23 18:10:49,956] Trial 11 finished with value: 0.3245636362253551 and parameters: {'epochs': 5, 'lr': 0.0010991230817356695, 'momentum': 0.6899429960128985}. Best is trial 6 with value: 0.3329202623857196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3592 Acc: 35.48% Kappa: 0.325\n",
      "Training complete in 87m 6s\n",
      "Best val Acc: 35.48%\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:03<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2955 Acc: 40.80% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:56<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3578 Acc: 36.38% Kappa: 0.336\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:40<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2944 Acc: 40.70% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3582 Acc: 36.01% Kappa: 0.334\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:42<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2914 Acc: 40.85% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3585 Acc: 35.68% Kappa: 0.332\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:40<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2900 Acc: 40.79% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3582 Acc: 35.68% Kappa: 0.329\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:40<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2905 Acc: 40.85% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:01<00:00,  1.04s/it]\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_18092\\1976785223.py:126: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'study_or_trial', 'file_path', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_18092\\1976785223.py:128: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'study_or_trial', 'file_path', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "C:\\Users\\TrendingPc\\AppData\\Local\\Temp\\ipykernel_18092\\1976785223.py:133: FutureWarning:\n",
      "\n",
      "upload_artifact() got {'study_or_trial', 'file_path', 'artifact_store'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3589 Acc: 35.65% Kappa: 0.334\n",
      "Training complete in 83m 48s\n",
      "Best val Acc: 36.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-23 19:34:38,703] Trial 12 finished with value: 0.3360896234955618 and parameters: {'epochs': 5, 'lr': 3.762122570550491e-05, 'momentum': 0.8597024913044766}. Best is trial 12 with value: 0.3360896234955618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:58<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2929 Acc: 40.81% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:56<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3583 Acc: 35.98% Kappa: 0.331\n",
      "Epoch 1/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:46<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2933 Acc: 40.83% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3594 Acc: 35.81% Kappa: 0.325\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:49<00:00,  4.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2907 Acc: 41.10% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3585 Acc: 35.78% Kappa: 0.326\n",
      "Epoch 3/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [16:04<00:00,  4.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2919 Acc: 41.21% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3586 Acc: 35.68% Kappa: 0.326\n",
      "Epoch 4/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [15:54<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2913 Acc: 40.77% Kappa: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:00<00:00,  1.03s/it]\n",
      "[I 2025-04-23 20:59:11,467] Trial 13 finished with value: 0.33265666737434607 and parameters: {'epochs': 5, 'lr': 2.710386435026171e-05, 'momentum': 0.2987051829151562}. Best is trial 12 with value: 0.3360896234955618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.3585 Acc: 36.28% Kappa: 0.333\n",
      "Training complete in 84m 33s\n",
      "Best val Acc: 36.28%\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///../work/db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=f'{MODEL_NAME}_{MODEL_VERSION}',\n",
    "                            load_if_exists = True)\n",
    "study.optimize(optuna_train, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
